## Title of the Project

**EmoSense: Intelligent Audio Sensitivity and Emotion Detection for Neurodevelopmental Support Systems**

---

## Small Description about the Project

An AI-driven web application that enables real-time emotion recognition, interactive visual learning, and intelligent audio sensitivity analysis to support children with neurodevelopmental conditions while providing caregivers with automated progress insights.

---

## About

<!--Detailed Description about the project-->  

EmoSense is a smart assistive learning system designed to enhance emotional understanding and sensory awareness in children with neurodevelopmental support needs. Traditional emotional learning and sensory assessment approaches rely heavily on manual observation, therapy sessions, and static visual materials, which often lack real-time interaction and measurable feedback.

This project introduces an intelligent web-based platform that uses deep learning–based facial emotion recognition and controlled audio exposure analysis to create an adaptive learning environment. The system converts detected emotions into intuitive emoji-based visual cues, tracks user responses across structured attempts, evaluates improvement trends, and automatically generates detailed progress reports for caregivers. By integrating computer vision, affective computing, and human-centered interaction, EmoSense provides a scalable and data-driven approach for personalized emotional and sensory learning support.

---

## Features

<!--List the features of the project as shown below-->  

* Real-time facial emotion recognition using deep convolutional neural networks (InceptionV3).
* Interactive emoji-based emotional learning interface.
* Multi-attempt response tracking with automated progress evaluation.
* Intelligent audio sensitivity detection through facial reaction monitoring.
* Automated email report generation for caregivers and educators.
* Scalable web-based deployment architecture.

---

## Requirements

<!--List the requirements of the project as shown below-->  

* **Operating System:** 64-bit Windows 10 / Ubuntu recommended for deep learning compatibility.
* **Development Environment:** Python 3.8 or later.
* **Deep Learning Frameworks:** TensorFlow and Keras for emotion recognition model training.
* **Computer Vision Library:** OpenCV for real-time facial detection and processing.
* **Dataset:** FER2013 facial expression dataset for supervised training.
* **Version Control:** Git for collaboration and project management.
* **IDE:** Visual Studio Code or similar development environment.
* **Additional Dependencies:** NumPy, Pandas, Matplotlib, scikit-learn, and Flask for web deployment.

---

## System Architecture

<img width="1536" height="1024" alt="ChatGPT Image Feb 5, 2026, 05_35_10 PM" src="https://github.com/user-attachments/assets/d9f40c6c-24d4-4ab6-b3bf-15ada69b520c" />


## Output



#### Output 1 – Emotion Detection Interface

*(Insert screenshot of real-time detected emotion result.)*

#### Output 2 – Interactive Learning and Feedback Screen

*(Insert screenshot of emoji-based learning feedback and response tracking.)*

**Model Accuracy:** ~95–97% training performance depending on dataset configuration.
*Note: Accuracy values can be updated based on final experimental evaluation.*

---

## Results and Impact

<!--Give the results and impact as shown below-->  

EmoSense improves emotional recognition, adaptive learning interaction, and sensory awareness through real-time AI-driven analysis. The integration of computer vision and affective computing enables caregivers and educators to better understand behavioral responses and learning progress using measurable insights.

The project contributes to the advancement of intelligent assistive technologies, promotes inclusive digital learning environments, and provides a scalable foundation for future multimodal emotional intelligence systems in healthcare and education domains.

---

## Articles Published / References

1. Rashidan, M. A., et al. “Technology-Assisted Emotion Recognition for Neurodevelopmental Conditions: A Systematic Review,” IEEE Access, 2021.
2. Chien, Y.-L., et al. “Game-Based Social Interaction Platform for Cognitive Assessment,” IEEE TNSRE, 2023.
3. Bartl-Pokorny, K. D., et al. “Robot-Based Intervention Review,” IEEE Access, 2021.
4. Prakash, V. G., et al. “Computer Vision-Based Behavioral Assessment,” IEEE Access, 2023.
5. Kurian, A., Tripathi, S. “Personalized Multimodal Emotion Recognition Framework,” IEEE Access, 2025.
